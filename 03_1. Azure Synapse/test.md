# Introduction

Azure Synapse Analytics includes **serverless SQL pools**, which are tailored for querying data in a **data lake**. With a serverless SQL pool, you can use **SQL code** to query data in files of various common formats without needing to load the file data into database storage. 

This capability helps **data analysts and data engineers** analyze and process file data in the data lake using a familiar data processing language, without the need to create or maintain a relational database store.

## Learning Objectives
After completing this module, you'll be able to:

- Identify **capabilities and use cases** for serverless SQL pools in Azure Synapse Analytics.
- Query **CSV, JSON, and Parquet files** using a serverless SQL pool.
- Create **external database objects** in a serverless SQL pool.

# Understand Azure Synapse Serverless SQL Pool Capabilities and Use Cases


Azure Synapse Analytics is an **integrated analytics service** that brings together a wide range of commonly used technologies for **processing and analyzing data at scale**. One of the most prevalent technologies used in data solutions is **SQL** - an industry-standard language for querying and manipulating data.

## Serverless SQL Pools in Azure Synapse Analytics
Azure Synapse SQL is a **distributed query system** in Azure Synapse Analytics that offers two kinds of runtime environments:

- **Serverless SQL pool**: On-demand SQL query processing, primarily used to work with data in a data lake.
- **Dedicated SQL pool**: Enterprise-scale relational database instances used to host **data warehouses**, in which data is stored in relational tables.

### **Benefits of Serverless SQL Pool**
In this module, we'll focus on **serverless SQL pool**, which provides a **pay-per-query endpoint** to query the data in your **data lake**. The benefits of using serverless SQL pool include:

‚úÖ **Familiar Transact-SQL Syntax**: Query data in place without the need to copy or load data into a specialized store.  
‚úÖ **Integrated Connectivity**: Supports a wide range of business intelligence and ad-hoc querying tools, including popular drivers.  
‚úÖ **Distributed Query Processing**: Built for large-scale data, leading to fast query performance.  
‚úÖ **Built-in Query Execution Fault-Tolerance**: Ensures high reliability and success rates, even for long-running queries involving large data sets.  
‚úÖ **No Infrastructure Setup**: No clusters to maintain. A built-in endpoint is provided within every Azure Synapse workspace, so you can start querying data immediately.  
‚úÖ **Cost-Effective**: No charge for reserved resources; you're only charged for the data processed by queries you run.  

### **When to Use Serverless SQL Pools?**
Serverless SQL pool is **tailored for querying data** residing in the data lake. Besides eliminating the **management burden**, it removes the need to worry about **ingesting the data into the system**. You simply **point the query to the data in the lake and run it**.

**Synapse SQL serverless resource model** is ideal for **unplanned** or "bursty" workloads. It enables **cost transparency**, allowing you to monitor and attribute costs **based on each executed query**.

üîπ **Note:**  
Serverless SQL pool is an **analytics system** and is **not recommended for OLTP workloads** (such as databases used by applications to store transactional data). Workloads requiring **millisecond response times** or pinpointing a **single row in a dataset** are **not a good fit** for serverless SQL pools.

### **Common Use Cases for Serverless SQL Pools**

#### **1Ô∏è‚É£ Data Exploration**
- Browse the **data lake** to gain **initial insights**.
- Easily achievable with **Azure Synapse Studio**.
- Use **built-in serverless SQL pool** to generate **SQL scripts** to select **TOP 100 rows** from a file or folder.
- Apply **projections, filtering, grouping**, and other SQL operations just as if the data were in a regular SQL Server table.

#### **2Ô∏è‚É£ Data Transformation**
- Azure Synapse Analytics provides **data transformation** capabilities with **Synapse Spark**.
- Some **data engineers** may prefer **SQL-based transformations**.
- Serverless SQL pool enables **SQL-based data transformations**, either **interactively** or as part of an **automated data pipeline**.

#### **3Ô∏è‚É£ Logical Data Warehouse**
- After **exploring data** in the data lake, define **external objects** such as **tables and views** in a serverless SQL database.
- The data **remains in the data lake files**, but is **abstracted** by a relational schema.
- Client applications and **analytical tools** can query the data **as if it were in a relational database hosted in SQL Server**.

## Use SQL to Query CSV Files

### Selecting and Querying CSV Data
1. Select the CSV folder.
2. In the **New SQL script** list on the toolbar, select **Select TOP 100 rows**.
3. In the **File type** list, select **Text format**, then apply settings to open a new SQL script.
4. In the **Properties** pane, rename **SQL Script 1** to **Query Sales CSV files**.
5. Change the result settings to show **All rows**.
6. Select **Publish** to save the script and hide the **Properties** pane.

#### Generated SQL Code:
```sql
-- This is auto-generated code
SELECT TOP 100 *
FROM OPENROWSET(
    BULK 'https://datalakexxxxxxx.dfs.core.windows.net/files/sales/csv/**',
    FORMAT = 'CSV',
    PARSER_VERSION='2.0'
) AS [result];
```

#### Modify the Query to Include Headers:
```sql
SELECT TOP 100 *
FROM OPENROWSET(
    BULK 'https://datalakexxxxxxx.dfs.core.windows.net/files/sales/csv/**',
    FORMAT = 'CSV',
    PARSER_VERSION='2.0',
    HEADER_ROW = TRUE
) AS [result];
```
7. Ensure **Built-in** is selected in the **Connect to** list.
8. Click **‚ñ∑ Run** to execute the SQL code.
9. Review the query results.

---
## Transform Data Using CETAS (CREATE EXTERNAL TABLE AS SELECT)

### Create an External Data Source and File Format
```sql
-- Database for sales data
CREATE DATABASE Sales
  COLLATE Latin1_General_100_BIN2_UTF8;
GO;

USE Sales;
GO;

-- External data is in the Files container in the data lake
CREATE EXTERNAL DATA SOURCE sales_data WITH (
    LOCATION = 'https://datalakexxxxxxx.dfs.core.windows.net/files/'
);
GO;

-- Format for table files
CREATE EXTERNAL FILE FORMAT ParquetFormat
    WITH (
        FORMAT_TYPE = PARQUET,
        DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'
    );
GO;
```
1. Rename the script to **Create Sales DB** and publish it.
2. Ensure the script is connected to the **Built-in SQL pool** and the **master database**, then run it.
3. Refresh the **Data** page and verify the creation of the **Sales** database and **sales_data** external data source.

---
## Create an External Table

### Retrieve and Aggregate Data
```sql
USE Sales;
GO;

SELECT Item AS Product,
       SUM(Quantity) AS ItemsSold,
       ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue
FROM OPENROWSET(
    BULK 'sales/csv/*.csv',
    DATA_SOURCE = 'sales_data',
    FORMAT = 'CSV',
    PARSER_VERSION = '2.0',
    HEADER_ROW = TRUE
) AS orders
GROUP BY Item;
```

### Save Query Results in an External Table
```sql
CREATE EXTERNAL TABLE ProductSalesTotals
WITH (
    LOCATION = 'sales/productsales/',
    DATA_SOURCE = sales_data,
    FILE_FORMAT = ParquetFormat
)
AS
SELECT Item AS Product,
       SUM(Quantity) AS ItemsSold,
       ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue
FROM OPENROWSET(
    BULK 'sales/csv/*.csv',
    DATA_SOURCE = 'sales_data',
    FORMAT = 'CSV',
    PARSER_VERSION = '2.0',
    HEADER_ROW = TRUE
) AS orders
GROUP BY Item;
```

1. Rename the script **Create ProductSalesTotals Table** and publish it.
2. Verify the table **ProductSalesTotals** in **External tables**.
3. Query the **ProductSalesTotals** table to verify aggregated sales data.
4. Confirm the creation of **productsales** folder in the data lake.
5. Verify Parquet files containing aggregated sales data.

---
## Encapsulate Data Transformation in a Stored Procedure

### Create a Stored Procedure to Aggregate Sales by Year
```sql
USE Sales;
GO;

CREATE PROCEDURE sp_GetYearlySales
AS
BEGIN
    -- Drop existing table
    IF EXISTS (
        SELECT * FROM sys.external_tables
        WHERE name = 'YearlySalesTotals'
    )
    DROP EXTERNAL TABLE YearlySalesTotals;
    
    -- Create external table
    CREATE EXTERNAL TABLE YearlySalesTotals
    WITH (
        LOCATION = 'sales/yearlysales/',
        DATA_SOURCE = sales_data,
        FILE_FORMAT = ParquetFormat
    )
    AS
    SELECT YEAR(OrderDate) AS CalendarYear,
           SUM(Quantity) AS ItemsSold,
           ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue
    FROM OPENROWSET(
        BULK 'sales/csv/*.csv',
        DATA_SOURCE = 'sales_data',
        FORMAT = 'CSV',
        PARSER_VERSION = '2.0',
        HEADER_ROW = TRUE
    ) AS orders
    GROUP BY YEAR(OrderDate);
END;
```
### Execute the Stored Procedure
```sql
EXEC sp_GetYearlySales;
```
1. Run the script to create the stored procedure.
2. Execute `EXEC sp_GetYearlySales;` to transform and store yearly sales data.
3. Verify the **yearlysales** folder in the data lake.
4. Delete the **yearlysales** folder before re-executing the stored procedure to avoid errors.







